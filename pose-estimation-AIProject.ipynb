{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f40a3a4-9d0b-495f-803e-3ab483a6b413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openvino as ov\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from typing import Tuple, Dict\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils import ops\n",
    "from ultralytics.utils.plotting import colors\n",
    "from pathlib import Path\n",
    "import random, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b8fb91e-0cc9-447a-8b5f-3c5d8396b91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenVINO model already exists.\n"
     ]
    }
   ],
   "source": [
    "ov_model = Path(\"model/yolov8n-pose_openvino_model/yolov8n-pose.xml\")\n",
    "if ov_model.is_file():\n",
    "    print(\"OpenVINO model already exists.\")\n",
    "\n",
    "else:\n",
    "    # Load a YOLOv8n PyTorch model\n",
    "    model = YOLO(\"model/yolov8n-pose.pt\")\n",
    "    \n",
    "    # Export the model\n",
    "    model.export(format=\"openvino\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42c46a1c-ae1e-4d9d-87d3-eb076de54462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input layer shape:  [1,3,640,640]\n",
      "Output layer shape: [1,56,8400]\n"
     ]
    }
   ],
   "source": [
    "core = ov.Core()\n",
    "\n",
    "model = core.read_model(model=\"model/yolov8n-pose_openvino_model/yolov8n-pose.xml\")\n",
    "pose_compiled_model = core.compile_model(model=model, device_name=\"CPU\")\n",
    "\n",
    "input_layer = pose_compiled_model.input(0)\n",
    "output_layer = pose_compiled_model.output(0)\n",
    "print(\"Input layer shape: \", input_layer.shape)\n",
    "print(\"Output layer shape:\", output_layer.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70afa714-a469-4c44-b3e4-61b5f3a9c03a",
   "metadata": {},
   "source": [
    "### PreProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf1d1cdb-7dd3-4887-a3ac-d34c03957cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def letterbox(img: np.ndarray, new_shape:Tuple[int, int] = (640, 640), \n",
    "              color:Tuple[int, int, int] = (114, 114, 114), auto:bool = False, \n",
    "              scale_fill:bool = False, scaleup:bool = False, stride:int = 32):\n",
    "\n",
    "    shape = img.shape[:2]                    \n",
    "    if isinstance(new_shape, int):           \n",
    "        new_shape = (new_shape, new_shape)   \n",
    "    \n",
    "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])    \n",
    "    if not scaleup:                                              \n",
    "        r = min(r, 1.0)                 \n",
    "\n",
    "    ratio = r, r      \n",
    "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
    "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  \n",
    "    if auto: \n",
    "        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  \n",
    "    elif scale_fill:  # stretch\n",
    "        dw, dh = 0.0, 0.0\n",
    "        new_unpad = (new_shape[1], new_shape[0])\n",
    "        ratio = new_shape[1] / shape[1], new_shape[0] / shape[0]  # width, height ratios\n",
    "\n",
    "    dw /= 2  \n",
    "    dh /= 2\n",
    "\n",
    "    if shape[::-1] != new_unpad:  # resize\n",
    "        img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)    \n",
    "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "    img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color) \n",
    "    return img, ratio, (dw, dh)\n",
    "\n",
    "\n",
    "def preprocess_image(img0: np.ndarray):\n",
    "\n",
    "    img = letterbox(img0)[0]\n",
    "\n",
    "    # Convert HWC(높이, 너비, 채널) to CHW(채널, 높이, 너비)\n",
    "    #               0,  1,   2      to       2,   0,   1\n",
    "    img = img.transpose(2, 0, 1)\n",
    "    img = np.ascontiguousarray(img)   # 입력된 배열을 C 스타일의 연속된 메모리 레이아웃을 갖는 배열로 변환\n",
    "    return img\n",
    "\n",
    "\n",
    "def image_to_tensor(image:np.ndarray):\n",
    "\n",
    "    input_tensor = image.astype(np.float32)  # uint8 to fp32 : 머신 러닝과 딥 러닝에서 수치 계산에 일반적으로 사용되는 데이터 유형\n",
    "    input_tensor /= 255.0                    # 0 - 255 to 0.0 - 1.0 정규화  : 딥러닝의 전처리 과정\n",
    "\n",
    "    # batch 차원 확장  - NCHW(배치크기, 채널, 높이, 너비) 형식 : tensorflow나 keras에서 기본적으로 NCHW 사용\n",
    "    if input_tensor.ndim == 3:\n",
    "        input_tensor = np.expand_dims(input_tensor, 0)\n",
    "    return input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "048e901a-3880-42a5-8457-72a1fa8ea97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(\n",
    "    pred_boxes:np.ndarray,\n",
    "    input_hw:Tuple[int, int],\n",
    "    orig_img:np.ndarray,\n",
    "    min_conf_threshold:float = 0.25,\n",
    "    nms_iou_threshold:float = 0.45,\n",
    "    agnosting_nms:bool = False,\n",
    "    max_detections:int = 80,\n",
    "):\n",
    "\n",
    "    nms_kwargs = {\"agnostic\": agnosting_nms, \"max_det\":max_detections}\n",
    "    preds = ops.non_max_suppression(\n",
    "        torch.from_numpy(pred_boxes),\n",
    "        min_conf_threshold,\n",
    "        nms_iou_threshold,\n",
    "        nc=1,\n",
    "        **nms_kwargs\n",
    "    )\n",
    "\n",
    "    results = []\n",
    "\n",
    "    kpt_shape = [17, 3]\n",
    "    for i, pred in enumerate(preds):\n",
    "        shape = orig_img[i].shape if isinstance(orig_img, list) else orig_img.shape\n",
    "        pred[:, :4] = ops.scale_boxes(input_hw, pred[:, :4], shape).round()\n",
    "        pred_kpts = pred[:, 6:].view(len(pred), *kpt_shape) if len(pred) else pred[:, 6:]\n",
    "        pred_kpts = ops.scale_coords(input_hw, pred_kpts, shape)\n",
    "        results.append({\"box\": pred[:, :6].numpy(), 'kpt': pred_kpts.numpy()})\n",
    "     \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807684ee-8f5e-4fd2-8bc5-381a1329ea45",
   "metadata": {},
   "source": [
    "# <img src=\"https://learnopencv.com/wp-content/uploads/2021/05/fix-overlay-issue.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e951c6d8-3514-4f71-b324-7f18a0cc164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle_between_points(a, b, c):\n",
    "\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    ba = a - b\n",
    "    bc = c - b  \n",
    "\n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = np.arccos(cosine_angle)\n",
    "\n",
    "    return int(np.degrees(angle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "babad2ce-67f0-421e-ada7-8563a8ce2734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_one_box(box:np.ndarray, img:np.ndarray, color:Tuple[int, int, int] = None, \n",
    "                 keypoints:np.ndarray = None, label:str = None, line_thickness:int = 5):\n",
    "\n",
    "    tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1  # line/font thickness\n",
    "    color = color or [random.randint(0, 255) for _ in range(3)]\n",
    "    c1, c2 = (int(box[0]), int(box[1])), (int(box[2]), int(box[3]))\n",
    "    cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n",
    "    angle = 180\n",
    "\n",
    "    if keypoints is not None:\n",
    "        a, b, c = None, None, None\n",
    "        skeleton = [[9, 7], [7, 5]]\n",
    "\n",
    "        # 관절 point 그리기\n",
    "        shape = img.shape[:2]\n",
    "        for i, k in enumerate(keypoints):\n",
    "            if i > 4 and i < 10:\n",
    "                x_coord, y_coord = k[0], k[1]\n",
    "\n",
    "                if x_coord % shape[1] != 0 and y_coord % shape[0] != 0:\n",
    "                    if len(k) == 3:\n",
    "                        if k[2] < 0.5:\n",
    "                            continue\n",
    "\n",
    "                    if i == 5:\n",
    "                        a = (x_coord, y_coord)\n",
    "                        cv2.circle(img, (int(x_coord),int(y_coord)), 5, (255, 51, 255), -1, cv2.LINE_AA)\n",
    "\n",
    "                    if i == 7:\n",
    "                        b = (x_coord, y_coord)\n",
    "                        cv2.circle(img, (int(x_coord),int(y_coord)), 10, (127, 0, 255), -1, cv2.LINE_AA)\n",
    "                        #각도 표기하기\n",
    "                        putAngle = (int(x_coord) - 70, int(y_coord) - 20)\n",
    "\n",
    "                    if i == 9:\n",
    "                        c = (x_coord, y_coord)\n",
    "                        cv2.circle(img, (int(x_coord),int(y_coord)), 5, (255, 51, 255), -1, cv2.LINE_AA)\n",
    "\n",
    "                    if None not in (a, b, c):\n",
    "                        angle = angle_between_points(a, b, c)\n",
    "                        cv2.putText(img, str(angle), putAngle, cv2.FONT_HERSHEY_PLAIN, 1, (255, 153, 51), 3, cv2.LINE_8)\n",
    "        ## 관절 선 그리기\n",
    "        ndim = keypoints.shape[-1]\n",
    "        for i, sk in enumerate(skeleton):\n",
    "\n",
    "            pos1 = (int(keypoints[(sk[0]), 0]), int(keypoints[(sk[0]), 1]))\n",
    "            pos2 = (int(keypoints[(sk[1]), 0]), int(keypoints[(sk[1]), 1]))\n",
    "           \n",
    "            if ndim == 3:\n",
    "                conf1 = keypoints[(sk[0]), 2]\n",
    "                conf2 = keypoints[(sk[1]), 2]\n",
    "                if conf1 < 0.5 or conf2 < 0.5:\n",
    "                    continue\n",
    "                    \n",
    "            if pos1[0] % shape[1] == 0 or pos1[1] % shape[0] == 0 or pos1[0] < 0 or pos1[1] < 0:\n",
    "                continue\n",
    "                \n",
    "            if pos2[0] % shape[1] == 0 or pos2[1] % shape[0] == 0 or pos2[0] < 0 or pos2[1] < 0:\n",
    "                continue\n",
    "\n",
    "            cv2.line(img, pos1, pos2, (0, 255, 0), thickness=2, lineType=cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    return img, angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f42f409-cff6-4b09-a4a9-33c21ccc6ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_results(results:Dict, source_image:np.ndarray):\n",
    "\n",
    "    boxes = results[\"box\"]\n",
    "    keypoints = results[\"kpt\"]                                   \n",
    "    \n",
    "    h, w = source_image.shape[:2]\n",
    "    angle = 180\n",
    "    for idx, (*xyxy, conf, lbl) in enumerate(boxes):\n",
    "        if conf < 0.4:\n",
    "            continue\n",
    "        label = f'{\"person\"} {conf:.2f}'\n",
    "        kp = keypoints[idx] if keypoints is not None else None\n",
    "        source_image, angle = plot_one_box(xyxy, source_image, keypoints=kp, label=label, color=colors(int(lbl)), line_thickness=1)\n",
    "    return source_image, angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "699c3d5c-c869-4326-ad61-e3ef52edb15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(image:np.ndarray, model:ov.Model):\n",
    "    preprocessed_image = preprocess_image(image)\n",
    "    input_tensor = image_to_tensor(preprocessed_image)\n",
    "\n",
    "    result = model(input_tensor)\n",
    "\n",
    "    #pro-processing\n",
    "    boxes = result[model.output(0)]                       # Extracting Boxes : 모델의 출력에서 bounding boxes를 추출\n",
    "    input_hw = input_tensor.shape[2:]                     # Input Dimensions(차수) 가져오기 : 예측된 상자의 크기를 원래 이미지 크기와 일치하도록 축소하는 데 필수적인 입력 텐서의 높이와 너비를 캡처\n",
    "    detections = postprocess(pred_boxes=boxes, input_hw=input_hw, orig_img=image)\n",
    "\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df37fff8-964a-423b-be12-ab3d17e4c558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddBackground(combined_image, bg):\n",
    "    bgimg = bg.copy()   \n",
    "    combined_image_h, combined_image_w = combined_image.shape[0], combined_image.shape[1] \n",
    "    new_w = 640\n",
    "    new_h = int((new_w/combined_image_w)*combined_image_h)\n",
    "    combined_image_resize = cv2.resize(combined_image, (new_w, new_h))\n",
    "    xmin = 270\n",
    "    ymin = 50\n",
    "    xmax = xmin + combined_image_resize.shape[1]\n",
    "    ymax = ymin + combined_image_resize.shape[0] \n",
    "    bgimg[ymin:ymax, xmin:xmax] = combined_image_resize\n",
    "    \n",
    "    return bgimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12f8958a-0999-4719-99d0-5045c157f950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Main():\n",
    "    camera = cv2.VideoCapture(0)\n",
    "    bg = cv2.imread(\"./data/background.jpg\")\n",
    "\n",
    "    score = 0\n",
    "    quizAngle = random.randint(3, 15) * 10\n",
    "    waitTime = 1\n",
    "    \n",
    "    while(True):\n",
    "        ret, frame = camera.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        detection = detect(frame, pose_compiled_model)[0]\n",
    "\n",
    "        image_with_boxes, angle = draw_results(detection, frame)\n",
    "        \n",
    "        # Quiz Box\n",
    "        cv2.rectangle(image_with_boxes, (0,0), (380, 73), (245,117,16), -1)\n",
    "\n",
    "        cv2.putText(image_with_boxes, 'angle Quiz', (10, 12), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image_with_boxes, str(quizAngle), (20, 60),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "        cv2.putText(image_with_boxes, 'Pose Angle', (150, 12), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image_with_boxes, str(angle), (155, 60),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,0), 2, cv2.LINE_AA)\n",
    "\n",
    "        cv2.putText(image_with_boxes, 'Score', (290, 12), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image_with_boxes, str(score), (290, 60),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0, 255), 2, cv2.LINE_AA)\n",
    "        gap = abs(quizAngle - angle)\n",
    "        if gap == 0:\n",
    "            score += 10\n",
    "            quizAngle = random.randint(3, 15) * 10\n",
    "            msg1 = \"Correct\"\n",
    "            cv2.putText(image_with_boxes, msg1, (150, 200),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 3, (0,255,255), 4, cv2.LINE_AA)\n",
    "            msg2 = \"Press any key to continue...\"\n",
    "            cv2.putText(image_with_boxes, msg2, (100, 300),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2, cv2.LINE_AA)\n",
    "            waitTime = -1\n",
    "            \n",
    "        deployment = AddBackground(image_with_boxes, bg)\n",
    "        cv2.imshow(\"Angle Quiz!!\", deployment)\n",
    "        cv2.waitKey(waitTime)\n",
    "        waitTime = 20\n",
    "        \n",
    "        if cv2.waitKey(waitTime) & 0xFF == ord(' '):\n",
    "            break\n",
    "\n",
    "\n",
    "    camera.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5b165fe2-65da-4794-949d-a63063cf52dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    Main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56018a63-1d73-4593-a759-2b79f0d39565",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
